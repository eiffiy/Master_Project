# Overview

## Introduction

### Background

Emotional expression plays an essential role in human interaction, which is a supplement of communications such as body gestures. A variety of forms of communication make people communicate more harmoniously. In some situations people will not tell their ideas directly, but others can understand by their emotions such like their facial expressions. This is an implicit way of communication.

As early as nineteenth century, facial expression analysis was proposed. In 1872, Darwin had published  the universality of facial expression in humans and animals, which was congenital and generated by long time living habits [1]. In the 1970's,  scholars presumed that six basic emotions possess distinct facial expressions [2], and these emotional displays are called *basic emotions* [3]. Basic emotions include happiness, sadness, fear, disgust, surprise and anger, which were considered about human ethnicities and culture[2]. Before 1978, facial expression analysis was an embranchment of psychologist research, until Suwa et al.[4] published the research results of automatic facial expression analysis, which was automatic analyzed from image database. After that, facial expression analysis investigation received more attention and researchers were increasingly focused on this field. It was caused by several factors. The main reason is, many related projects or areas  made great progress such as face recognition and face detection technology. These connected studies inspired the development of facial expression analysis. At the same time, improvements in computer performance also made complicated analysis possible. 

### Reason of Facial Expression Recognition

With the development of the area of robotics,  researchers try to adopt artificial intelligence in advanced robots which allows robots to communicate more naturally with human[5]. Apart from understanding speech, comprehending humans' emotions is also important because only by correctly acquiring human emotions, robots and human communication can be closer to the real situation. Therefore, recognition of facial expression to understand emotions is a key part.

### Difficulty of Facial Expression Recognition

Human can easily recognize others emotions through facial expressions, the millions of years of evolution make the human brain cleverly deal with facial information. However, it is a serious challenge for the machines. There are individual differences in human beings, this increases the difficulty of machines' analysis. Some primary challenges trouble the recognition, which contain variations in factors: lighting, pose, imaging modalities, occlusions[6]. In addition, differences in image qualities caused by image compression formats, image blurriness and diversification in photography angles impact the performance of facial expression recognition algorithms. Wechsler [7] indicated algorithms shows high correct rate in a controlled situation, but in uncontrolled environments all algorithms perform sharp decrease. 

Facial muscles would make change when people react for different situations, and this change leads to people's expression out of the ordinary state. As has been discussed above, human can understand these expressions. For example, if a expression show that the lips rises on a face, this person could be smile. Other expressions are more difficult to detect,  mouth, eyes, jaw, eyebrow, nostril even tongue can form complex combination. However, some expressions are similar, even if many people cannot recognize others' emotions; and everyone's facial organs are different in size and shape, if there is a person who is not well known by others, other people could not understand this person's emotion by his or her expressions. This also can influence machine's judgment. 

### Some Classification of Facial Expression Recognition Methods

Roychowdhury and Emmons[6] pointed out that all face and expression recognition methods can be broadly classified into two categories. One category of algorithms try to analyze the holistic faces and do the recognition works by processed images or data after Eigen-Face decomposition[8], which perform well in computation efficiency but are lack of adaption in environments. If the pose or image quality change, the performance of methods could be struggling. The second category of algorithms use Facial Action Units method which can extract facial parts automatically to find out relations between FAUs[9]. This category of algorithms can avoid influence of pose or image quality, but the cost of computation and time are also intensive. 

These two categories could widely include face and facial expression recognition area, but more specific categories of facial expression recognition  can be concluded in [15] and [16]. There are two primary research directions among facial expression recognition, the feature-based orientation and the template-based orientation [17]. The method that they extract facial expression information is that they are classified. The feature-based research direction extracts features from texture, or makes use of datasets' geometrical information to train models. The template-based  direction utilizes facial or head models in 2-Dims and 3-Dims as templates to obtain facial expression information. Model template-based methods can be found in [18,19], they used 3-Dims model to build a head, and according to its muscles' similarity to every specific expression to classify different expression. And if the model is 2-Dims, the recognition would base on some decision rules which was designed for 2_Dims facial models.

The former research direction shows more active than the template one. Before the twenty-first century, neural network and Gabor wavelets are two distinguished holistic methods of expression recognition, there were some researches [10,11] that combine these two methods and other local algorithms for experiments; of course, some researchers just used neural network[12] or connected neural network with Principal Components Analysis (PCA) to carry out analysis and research[13,14]. Bayesian Network [20], Support Vector Machines [21], and K-nearest neighbor [22] are also taken part in facial expression recognition and made some achievements. Generally speaking, a number of effective attempts in facial expression analysis researches can be found in recent 20 years [24-32].

### Deep Learning and Facial Expression Recognition

Nevertheless, deep learning algorithms, as an embranchment of neural network,show more possibility in facial expression recognition research. Although neural network has used in expression recognition for many years, deep learning was not popular all the time. One reason is that the neural network encountered bottlenecks in the last century, slow development caused that researchers did not think neural networks will become the mainstream machine learning method in the future, and this also aggravated the slow development of the neural network. At the same time, many outstanding algorithms were provided and some old algorithms were improved by researchers. The second reason is the improvement of research environment, remarkable Graphics Processing Unit (GPU) developed and the computational capability can content deep learning's requirements.

Deep Belief Networks (DBN) [35] and Convolutional Neural Networks (CNN) are two representative Artificial Neural Network, and these two neural networks use different respective but all obtained good effects in facial expression analysis. 

DBN has a robust ability in unsupervised feature learning, and can combine with Multilayer Perceptron (MLP) to generate a new system which is good at facial expression [33,34]. It is consisted by ordered superimposed Restricted Boltzmann Machine (RBM) [36]. CNN is a feed-forward artificial neural network and can be used in multi-class classification. In 2012, A. Krizhevsky, I. Sutskerver and G. E. Hinton [37] trained a deep convolutional neural network system which tried to classify the 1200000 high resolution picture images in 1000 different classes and gained excellent results compared with other systems in the same period. The classification ability of CNN has been proved and it also can used in facial expression recognition fields. This article would make detailed interpretation of CNN in next chapter, and use CNN as main algorithm to build a facial expression recognition system. 

### Facial Expression Analysis System Basic Structure

Facial expression analysis can be separated into two main sections, measurement facial procedure and expression recognition procedure. There are three steps which contain methods of automatic facial expression analysis: face acquisition, facial data extraction and representation, and facial expression recognition [23].

Face acquisition is a procedure that system try to find faces automatically in the input images or videos. It need to generate a detector and find the regions of the face in the images or sequences, which can be picked up and carry on	the following procedures. This system should have the ability to process the serious shift of the head in the video materials, to track the head and try to obtain fixed facial information [23].

When faces are located successfully, these facial images can be extracted the facial transformation information generated by expressions. The feature extraction method is the key point of analysis, it decides models' quality that would be trained [23]. There are many algorithms of feature extraction had been provided and used in this field, some of them had been mentioned in this article.

The last part of the automatic facial expression analysis system is the recognition stage, which uses the trained model to analyze input images or other materials.



#### Reference

###### [1] C. Darwin, The Expression of the Emotions in Man and Animals, J. Murray, London, 1872.

###### [2] P.Ekman, W.V.Friesen, Constants across cultures in the face and emotion, J. Personality Social Psychol. 17 (2) (1971) 124-129

###### [3] B.Fasel, Juergen Luettin, Automatic Facial Expression Analysis: A Survey, 2002.

###### [4]  M. Suwa, N. Sugie, K. Fujimora, A preliminary note on pattern recognition of human emotional expression, Proceedings of the Fourth International Joint Conference on Pattern Recognition Kyoto, Japan, 1978, pp. 408-410.

###### [5] P. Burkert, F. Trier, M. Z. Afzal, A. Dengel, M. Liwicki, DeXpression: Deep convolutional Neural Network for Expression Recognition, 2016.

###### [6] S. Roychowdhury, M. Emmons, A Survey of The Trends in Facial and Expression Recognition Databases and Methods, International Journal of Computer Science & Engineering Survey, 2015, 6, 1-19.

###### [7] H. Wechsler, Face recognition Methods for Uncontrolled Settings, Face Recognition in Adverse Conditions(2014): 38.

###### [8] Turk, Matthew, and Alex P. Pentland. "Face recognition using eigenfaces." IEEE Computer Society Conference Vision and Pattern Recognition, 1991, pp.586-591.

###### [9] Tian, Yang-li, Takel Kanade, and Jeffrey F. Cohn. "Recognizing action units for facial expression analysis." IEEE Transactions on Pattern Analysis and Machine Intelligence, 23.2(2001): 97-115.

###### [10] W. Fellenz, J. Taylor, N. Tsapatsoulis, S. Kollias, Comparing template-based, feature-based and supervised classification of facial expressions from static images, Proceedings of Circuits, Systems, Communications and Computers (CSCC'99), Bugata, Japen, 1999, pp. 5331-5336.

###### [11] M. Dailey, G. Cottrell, PCA Gabor for expression recognition, Institution UCSD, Number CS-629, 1999.

###### [12] C. Lisetti, D.Rumelhart, Facial expression recognition using a neural network, Proceedings of the 11th International Flairs Conference, AAAI Press, New York, 1998.

###### [13] C. Padgett, G. Cottrel, Representing face image for emotion classification, in: M. Mozer, M. Jordan, T. Petsche (Eds. ), Advances in Neural Information Processing Systems, Vol. 9, MIT Press, Cambridge, MA, pp. 894-900.

###### [14] G.W. Cottrel, J. Metcalfe, EMPATH: face, gender and emotion recognition using holons, in: R. Lippman, J. Moody, D. Touretzky (Eds. ), Advances in Neural Information Processing Systems, Morgan Kaufman, San Mateo, CA, Vol. 3, 1991, pp. 564-571. 

###### [15] ——, “Automatic analysis of facial expressions: The state of the art,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 22, no. 12, pp. 1424–1445, Dec. 2000.

###### [16] B. Fasel and J. Luettin, “Automatic facial expression analysis: A survey,” Pattern Recognit., vol. 36, no. 1, pp. 259–275, 2003.

###### [17] I. Kotsia, I. Pitas, "Facial Expression Recognition in Image Sequences Using Geometric Deformation Features and Support Vector Machines," EEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 16, NO. 1, JANUARY 2007.

###### [18] I. A. Essa and A. P. Pentland, “Facial expression recognition using a dynamic model and motion energy,” presented at the Int. Conf. Com- puter Vision, Cambrdige, MA, Jun. 20–23, 1995.

###### [19] ——, “Coding, analysis, interpretation, and recognition of facial ex- pressions,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 19, no. 7, pp. 757–763, Jul. 1997.

###### [20] J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann, 1988.

###### [21] C. Cortes, and V. Vapnik, “Support-vector networks,” Mach. learn., Vol. 20, no. 3, pp. 273 97, Sep. 1995.

###### [22] T. Cover, and P. Hart, “Nearest neighbor pattern classification,” IEEE Trans. Inform. Theor., Vol. 13, no. 1, pp. 21 7, Jan. 1967.

###### [23] Y. Tian, T. Kanade, J.F.Cohn, "Handbook of Face Recognition, Chapter 19: Facial Expression Recognition," pp147-175, Jan. 2011. 

###### [24] Bartlett, M., Littlewort, G., Frank, M., Lainscsek, C., Fasel, I., Movellan, J.: Automatic recognition of facial actions in spontaneous expressions. J. Multimed. 1(6), 22–35 (2006)

###### [25] Black, M., Yacoob, Y.: Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motion. In: Proc. of International Conference on Computer Vision, pp. 374–381 (1995)

###### [26] Black, M., Yacoob, Y.: Recognizing facial expressions in image sequences using local parameterized models of image motion. Int. J. Comput. Vis. 25(1), 23–48 (1997)

###### [27] Cohn, J., Zlochower, A., Lien, J., Kanade, T.: Automated face analysis by feature point tracking has high concurrent validity with manual facs coding. Psychophysiology 36, 35–43 (1999)

###### [28] Donato, G., Bartlett, M., Hager, J., Ekman, P., Sejnowski, T.: Classifying facial actions. IEEE Trans. Pattern Anal. Mach. Intell. 21(10), 974–989 (1999)

###### [29] Essa, I., Pentland, A.: Coding, analysis, interpretation, and recognition of facial expressions. IEEE Trans. Pattern Anal. Mach. Intell. 19(7), 757–763 (1997)

###### [30] Fukui, K., Yamaguchi, O.: Facial feature point extraction method based on combination of shape extraction and pattern matching. Syst. Comput. Jpn. 29(6), 49–58 (1998)

###### [31] Gunes, H., Piccardi, M.: Automatic temporal segment detection and affect recognition from face and body display. IEEE Trans. Syst. Man Cybern., Part B, Cybern. 39(1), 64–84 (2009)

###### [32] Rosenblum, M., Yacoob, Y., Davis, L.: Human expression recognition from motion using a radial basis function network architecture. IEEE Trans. Neural Netw. 7(5), 1121–1138 (1996)

###### [33] X. Zhao, X. Shi, S. Zhang, "Facial Expression Recognition via Deep Learning", IETE Technical Review, Vol 32, NO 5, Sep-Oct 2015.

###### [34] Y. Lv, Z. Feng, C. Xu, "Facial Expression Recognition via Deep Learning," IEEE, pp.303-308, 2014.

###### [35] G. E. Hinton, S. Osindero, and Y.-W. Teh, “A fast learning algo- rithm for deep belief nets,” Neural Comput., Vol. 18, no. 7, pp. 1527 54, Jul. 2006.

###### [36] Y. Freund, and D. Haussler, “Unsupervised learning of distribu- tions of binary vectors using two layer networks,” University of California, Santa Cruz, CA Tech. Rep. UCSC-CRL-94-25, 1994.

###### [37] A. Krizhevsky, I. Sutskerver and G. E. Hinton, "ImageNet Classification with Deep Convolutional Neural Networks", NIPS, 2012.